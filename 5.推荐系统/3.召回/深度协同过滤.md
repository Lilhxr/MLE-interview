# 深度协同过滤

##### 1. 协同过滤的思想



implicit data: 用户的点击/购买行为

explicit data: user对item的评分矩阵

![Image of the same feedback matrix. This time, each user and each movie is mapped to a two-dimensional embedding (as described in the previous figure), such that the dot product of the two embeddings approximates the ground truth value in the feedback matrix.](https://developers.google.com/machine-learning/recommendation/images/2Dmatrix.svg)

那么，怎么去获得这个user-item二分图中每个节点的表示呢？其实，所有的方法可以分成两类：基于降维的方法(dimensionality reduction-based approaches)和基于深度学习的方法（NN-based approaches）。

其中，基于降维的方法就是矩阵分解(matrix factorization)。基于矩阵分解的协同过滤把userID和itemID打成embedding，让其试图恢复原先的user-item矩阵，然后在未见的user-item交互中预测该处user-item矩阵的值（用点积来计算），其本质就是矩阵补全问题。

> Dimensionality reduction-based approaches optimize a function that reduces the dimension of a graph matrix (user-item矩阵) and then produce low-dimensional embeddings.

我们要理解的一点是，user-item矩阵中为0的项并不代表用户对此商品不感兴趣 -- 有可能这个商品根本就没有曝光，我们不知道用户对它的兴趣（exposure bias），所以user-item矩阵是有噪声的。

##### 2. Neural MF

我们可以用神经网络来模拟矩阵分解的过程，例如 Neural Collaborative Filtering (WWW2017) 用神经网络来训练user/item的隐向量，然后通过MLP得到最终的得分。这样可以避免巨大的user-item矩阵直接分解。

损失函数可以是point-wise loss（MSE或者log loss）；也可以是pair-wise loss（需要给正样本比负样本高的分数）。

![img](https://pica.zhimg.com/80/v2-20283d39f57a56ed5a6e91dd350d7e91_1440w.png)

##### 2. 图网络做协同过滤

##### 2.1 Neural Graph Collaborative Filtering (SIGIR 2019)：显式把握高阶关系信息

基于矩阵分解的协同过滤得到user/item 的 ID embedding，不免会遇到**数据稀疏**问题。同时，矩阵分解的协同过滤**只能把握一阶的user-item关系，不能得到高阶的关系**。何谓“高阶的连接”？下图中i4->u2->i2->u1就是一个高阶的关系。user2喜欢item2，同时user1也喜欢item2，这就把user1和user2显式的连接起来了。

![img](https://pic1.zhimg.com/80/v2-feffda0f5a3525b285c700cfd6f66d0c_1440w.png)

为了得到**显式的高阶的连接性(high-order connectivity)**, 我们把user-item矩阵用一个图来表示。让图**聚合**k次邻居节点的信息，就能够把握住k阶的连接性。如上图中，聚合两次就可以显式把握住u1->i2->u2的联系，聚合三次就可以显式把握住u1->i2->u2->i4的联系。

具体的做法是，首先将经过MF得到的user/item ID embedding作为每个节点的**初始化**embedding；然后，在图上对邻居（user的邻居是item，item的邻居是user）进行**聚合**以把握住高阶的连接关系，以此来对MF得到的初始embedding做更精细的调整(refine). 下面，我们来详细介绍图中是如何聚合的。

1）信息传递

对于相连的user-item对(u,i), i传到u的信息计算公式：

![img](https://pic3.zhimg.com/80/v2-f89133cc1f642cd880c95fd438cf05c9_1440w.jpeg)

和普通的GCN邻居聚合方法不同的是，这里还增加了item embedding和邻居user embedding的哈达玛积，引入了交互信息。那么，第一次聚合之后，user的表示为：

![img](https://pic2.zhimg.com/80/v2-b727f0391bdbda5c056aeed942276f75_1440w.png)

即为user本身，传到user的信息+所有邻居item传到user的信息。经过L次如此的聚合，我们就可以得到融合了L阶关系的user/item embedding。这L个不同阶的embedding我们可以将他们进行拼接/加权/过LSTM等方式融合，得到最终的user/item embedding。这个embedding比起简单的用矩阵分解方式得到的embedding就融合了不同阶的user-item交互信息，因此包含的信息更为丰富了。

这样，我们就得到了user/item embedding，二者求点积即为预测的得分（相似度）。损失函数选用pair-wise的Bayesian personalized ranking (BPR) loss，即：

![img](https://pic3.zhimg.com/80/v2-3ecec4de701beadbb5ca95590b774048_1440w.png)

其中，i为正样本，j为负样本。

##### 2.2 异构图网络做协同过滤：把握user-user和item-item的内容相似度信息

一个user/item的表征可以看成由两部分组成：内容本身(content-based)的表征，和在user-item图中的关系表征。上述讲的Graph MF方法只是利用了user-item矩阵，但是并没有考虑到user-user和item-item**基于内容的**相似度。

因此，我们除了根据评分矩阵建立user-item图（user-item边上的权重为归一化的评分），同时还可以在图上根据user-user和item-item的内容相似度构建user-user和item-item之间的边（边权重为归一化的相似度）。这里节点的初始化embedding可以是经过MF得到的embedding与user/item内容信息的某种组合。之后，我们使用一些graph embedding方法（DeepWalk，GraphSAGE等），得到user/item的embedding。

例如之前将跨域推荐的时候提到的： [Graphical and Attentional Framework for Dual-Target Cross-Domain Recommendation](https://link.zhihu.com/?target=https%3A//www.ijcai.org/proceedings/2020/0415.pdf) [ijcai, 2020] 的第二层 graph embedding layer就是用这样的异构图来得到好的user/item embedding。

这样做的另一个好处是可以一定程度上解决冷启动问题。对于一个新来的item，我们虽然不知道它和user的交互信息是什么样子，但是我们可以知道它的content信息，这样就能够算出来它和其他item的相似度，就可以连接起它和图中的其他item。这样，通过GraphSAGE做几次聚合之后，我们就能够得到一个比较好的初始化embedding。

![img](https://pic4.zhimg.com/80/v2-e2bc71135409dadff199ffa8a27f364b_1440w.jpg)