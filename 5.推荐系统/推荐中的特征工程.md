# 推荐中的特征工程

**搜索场景**，用户意图是主动明确的，目标是更快找到需要的物品；**推荐场景**用户的兴趣是模糊的，目标是推荐给他多样的、准确的（这两个目标是个trade-off）的物品。

例如，在搜索场景，由于Prefix或Query的限制，召回的物品得满足相关性，一些向量召回方法就不易发挥用处。另一方面，推荐系统不同阶段的特点对特征和模型也有所限制，例如，**召回阶段**面对的是海量的候选集，只能上简单的特征和模型粗略选出用户可能会感兴趣的物品，而**排序阶段**的候选集的规模较小，可以上复杂的特征和模型更精确地预估用户对物品的感兴趣程度。



## 1. 序列

- **1.1 行为类型**：点击，收藏，成交是不同的interaction种类，可以分别表示用户的短期，中期，长期兴趣，既可以组织为一个混合序列、并通过interaction类别特征进行区分（Perceive Your Users in Depth: Learning Universal User Representations from Multiple E-commerce Tasks https://arxiv.org/abs/1805.10727），也可以直接组织为多个种类的序列分别建模 -- 用户对近期点击过的商品大概率仍然感兴趣，但对于近期购买过的商品一般短期内不再感兴趣（需求已被满足）。

- **1.2 行为时间**

- - 该行为距离当前query的时间差。一般来说，用户当前的兴趣与近期行为过的物品更相关。
  - 在当前物品上的停留时间。例如，用户在购买某一商品时在详情页的停留时间，停留时间越长一般越感兴趣。

- **1.3 行为场景**：对一个商品的点击可以发生在首页推荐，搜索推荐和广告推荐[1]，同一种行为在不同场景下含有不同的意义。

- **1.4 物品种类**：行为序列中的物品可以是Query，Item，Review，Music，Movie，Book，Food等，视业务场景而定。

- **1.5 物品属性**：如果只使用物品ID特征，长尾物品在样本和序列中占比都很低，其ID Embedding不容易学好，因此可以加入类目，品牌，店铺等**泛化特征**[1]，同时模型也能学习到更泛化的偏好，例如某一用户更喜欢购买阿迪达斯品牌的商品。

- **1.6 序列划分**

- - **多种兴趣**：用序列模型抽取行为序列信息得到用户的兴趣向量，考虑到序列内物品的异构性，单一的兴趣向量难以精确地表征用户的兴趣偏好，例如，某个用户的行为序列内既有服饰类商品又有电子类商品，将对不同类目商品的兴趣融合到一个向量内容易导致“四不像”。一个典型的例子是推荐场景的召回阶段，单一的兴趣向量召回的商品往往比较杂甚至不相关。因此，我们可以对行为序列进行划分，一方面，可以根据某个准则**手动划分**，例如，根据**类目特征**将商品分类、根据**时间窗口划分Session**（同一Session内的物品更相关）；另一方面，也可以使用**胶囊网络（MIND）**，**记忆单元（MIMN）**等动态学习兴趣划分。事实上，**Multi-head Attention**也能学习到这样的多种兴趣。
  - **长短兴趣**：根据时间跨度可以将序列划分为短期序列和长期序列，分别用来表征用户的短期兴趣和长期兴趣（相对稳定）。一方面，**可以设置一个时间窗口划分长短期序列分别学习再做融合**[9,10]，另一方面，**也可以用记忆网络来学习长期兴趣**。一般来说，用户当前的行为主要受短期兴趣的影响。

- **1.7 超长序列**：加长序列可以引入更丰富的用户历史行为，但是序列模型在处理时计算量大且RT高。因此，一方面，**可以根据某个规则快速筛选出超长序列中与Target相关的物品**，例如，同一类目下的物品、Embedding接近的物品（LSH）等[12]，另一方面，**可以合理设计网络结构并利用记忆网络学习**，将兴趣向量的更新与候选物品的打分解耦（MIMN）。





算法工程师就好比厨师，模型是灶上功夫，而数据预处理+特征工程就好比刀工。再好的食材，不切不洗，一古脑地扔下锅，熟不熟都会成问题，更甭提味道了。好的刀工能够将食材加工成合适的形状，无需烈火烹油，也能做出好味道。同理，特征工程做得好，简单模型也能做出不错的效果，当然有了nb的模型，“或许”能够锦上添花。

有没有比刀工更重要的呢？好的厨师要擅于挑选食材，所以好的算法工程师要会挑选数据。例如《负样本为王》一文中提到的，负样本挑错了，再好的特征工程也无法挽救你的召回模型。



### 1. 基础套路（常规原始特征）

- 用户侧无非就是人口属性（性别、年龄、职业、位置等）、用户安装的app列表、用户的各种观看+互动历史；
- 物料侧无非就是基本属性（作者、长度、语言等），还有基于内容理解（thanks to nlp and cv）技术打上的一堆一/二级分类、标签、关键词等

这些未经加工的原始信息发挥的作用有限。即使是对于新用户，一些产品同学往往以为知道了用户的性别、年龄，甚至安装的app，就能猜出用户兴趣，从而提升冷启动中的个性化成分，结果往往令人失望。

其次，我还是要再次批判“深度学习使特征工程过时”的论调。比如，用了阿里的DIxN家族（DIN/DIEN/DSIN）能够捕捉用户的短期兴趣，用了SIM能够捕捉用户的长期兴趣，那么未来是不是没必要再对用户历史做特征工程了，把一堆用户观看+互动过的item id扔进DIxN+SIM不就行了，省时省力，效果也好？我的答案是否定的，原因有二：

- 2021年留给我最深印象的就是DCN作者的那一句话“People generally consider DNNs as universal function approximators, that could potentially learn all kinds of feature interactions. However, recent studies found that DNNs are inefficient to even approximately model 2nd or 3rd-order feature crosses.”。DNN的“火力”没那么强，原材料一古脑扔进去，有时熟不熟都会成问题，更何况各种滋味的融会贯通。
- 各种强大的网络结构好是好，但并不是无代价的。SIM中用target item去检索用户的长期历史再做attention，都是线上inference的耗时大头。做做候选item只有几百的精排倒还可以，但是让候选item有成千上万的粗排和召回，情何以堪？难道不用SIM就不能刻画用户的长期兴趣了吗？当然不是，接下来要介绍的几个特征工程上的技巧就能够派上用场。**将计算压力从线上转移到线下，离线挖掘用户长期兴趣，使召回+粗排环节也能够用得上**。

接下来，就介绍推荐系统特征工程中的几个高级技巧，将原始特征加工成“**让模型更好吸收**”的形状。

### 2. 用户特征

无疑，描述用户兴趣最有用的信息就是各种用户**历史**。如上所述，除了将用户观看+交互过的item id一古脑地扔进DIN/DIEN/SIM，让模型自己学出用户各种长短期历史，我们还可以从这些用户历史中手工挖掘出一些有用的信号。

我的一个同事提出从以下6个维度挖掘用户的长短期兴趣

- 用户粒度

- - 单个用户
  - 某一群用户：比如相同年龄段、同性别、同地域、安装了同款app的人群。**基于人群的统计，对于新用户冷启意义重大**。

- 时间粒度

- - 最近、过去x小时、过去1天、过去1周、过去1月、从用户首次使用app至今、...
  - 太长的时间粒度（e.g.,首次使用至今）在统计的时候，会考虑时间衰减
  - 长期历史的统计，会通过离线批量任务（hadoop/spark）的形式完成
  - 短期历史的统计，会直接访问线上缓存（redis）

- 物料粒度

- - 可以是item id
  - 也可以是item上的属性，比如一二级分类、标签、关键词、...

- 动作类型

- - 正向：点击、有效观看、完整观看、点赞、转发、评论、...
  - 负向：忽略（曝光未点击）、短播、踩、...

- 统计对象

- - 次数、时长、金额、...

- 统计方法

- - 收集成列表、计算XTR、计算占比、...

通过以上6个维度的交叉，我们可以构造出一系列特征来描述用户的长期（e.g., 首次使用app至今）、短期（e.g. 过去1天）、超短期（e.g., 刚刚观看的x个视频）的兴趣。比如：

- 用户A，在过去1天，对tag="坦克"的CTR（i.e., 系统在过去1天，给该用户推了10篇带tag="坦克"的文章，该用户点击了6篇，ctr=0.6）
- 用户A，在过去1天，对tag=“坦克”的点击占比（i.e., 在过去1天，用户一共点击了10文章，其中6篇带tag="坦克"，点击占比=0.6）
- 用户A，在过去1天，对tag=“坦克”的时长占比（i.e., 在过去1天，用户一共播放了100分钟，其中60分钟消费在带tag="坦克"的物料上，时长占比=0.6）
- 用户A，在最近1小时，点击的文章列表
- 用户A，在过去1天，忽略（隐式负反馈）category=“时尚”的item个数
- 用户A，自首次使用app至今，对tag='坦克'的CTR（统计时，曝光数与点击数都要经过时间衰减）
- 男性用户，在过去1月，对tag="坦克"的文章的CTR

注意：

- 以上6个维度只是为我们手工挖掘用户兴趣提供了一个框架，使我们添加特征时更有章法。至于具体要离线挖掘哪些特征，也要根据算力和收益，综合考虑；
- 这些手工挖掘的用户兴趣信号，**可以作为DIN/DIEN/SIM挖掘出来的用户兴趣的补充**。而在召回/粗排这种计算压力大的环节，由于可以离线挖掘而节省线上耗时，以上这些**手工挖掘出的用户长短期兴趣可以（局部）代替DIxN/SIM这些“强但重”的复杂模型**。

# 物料特征

对于item侧，我认为最重要的特征就是这些item的后验统计数据，

- 时间粒度：全部历史（带衰减）、过去1天，过去6小时，过去1小时、......
- 统计对象：CTR、平均播放进度、平均消费时长、......

比如：某文章在过去6小时的CTR，某文章在过去1天的平均播放时长、......

但是也要谨记，

- 这些统计数据肯定是**有偏**的，一个item的后验指标好，只能说明推荐系统把它推荐给了对的人，并不意味着把它推给任何人都能取得这么好的效果。

- - 其实这个问题其实也不大，毕竟交给精排模型打分的都已经通过了召回+粗排的筛选，多多少少是和当前用户相关的，之前的统计数据还是有参考意义。

- 利用这些后验统计数据做特征，多少有些纵容马太效应，之前后验数据好的item可能会被排得更靠前，不利于新item的冷启。

- - 那么新item没有后验证数据怎么办？填写成0岂不是太受歧视了？其实有一个办法就是**建立一个模型，根据物料的静态信息（e.g., 作者、时长、内容理解打得各种标签等基本稳定不变的信息）来预测它们的后验数据**。

------

另外再介绍一个**由用户给物料反向打标签**的trick。

- 一般画像的流程，都是先有物料标签，再将用户消费过的物料的标签积累在用户身上，形成用户画像。
- 反向打标签是指，将消费过这个物料的用户身上的标签积累到这个物料身上。比如：一篇关于某足球明星八卦绯闻的文章，由于该明星的名字出现频繁，NLP可能会将其归为“体育新闻”，但是后验数据显示，带“体育”标签的用户不太喜欢这篇文章，反而带“娱乐”标签的用户更喜欢，显然这篇文章也应该被打上“娱乐”的标签。
- 类似的，给物料打上“小资文青喜欢的top10电影之一”，或者“在京日本人光顾最多的日料店”等，都是由用户消费反向给物料打上的极其重要的标签。

# 交叉特征

说到交叉特征，受“DNN万能论”的影响，近年来已经不再是研究+关注的热点。既然DNN"能够"让喂入的特征“充分”交叉，那何必再费神费力地去做交叉特征。

我的答案还是那两条，一来，不要再迷信DNN"万能函数模拟器"的神话；二来，手动交叉的特征犹如加工好的食材，这么强烈的信号递到模型的嘴边上，模型没必要费力咀嚼，更容易被模型消化吸引。

比较简单的一种交叉特征就是计算用户与物料在某个维度上的相似度。以“标签”维度举例：

- 某用户过去7天在“标签”维度上的画像，可以写成一个稀疏向量，`u={‘坦克’:0.8, ‘足球’:0.4, '二战':0.6, '台球':-0.3}`。每个标签后面的分数是由第2节的方法统计出的用户在某个标签上的兴趣强度（可以根据xtr/时长等指标计算出）；
- 某篇文章的标签，可以写成一个稀疏向量，`d={'坦克':1, '二战':0.5, '一战':0.8}`。每个标签后面的分数是NLP在打这个标签时的置信度；
- 拿这两个稀疏向量做点积，`u x d={‘坦克’:0.8, ‘足球’:0.4, '二战':0.6, '台球':-0.3} x {'坦克':1, '二战':0.5, '一战':0.8}=0.8*1+0.5*0.6=1.3`，就可以表示这个用户对这篇文章在“标签”维度上的匹配程度。

------

另一个复杂一点的交叉特征是**任意一对儿<user特征，item特征>上的消费指标**，比如`<男性用户，item标签=“足球”>`这一特征对上的xtr。要得到这样的特征，离线统计当然是可以的，数数`<男性用户，item标签=“足球”>`共同出现的样本有多少，其中带正标签的样本又有多少，两者一除就能得到。但是这么做，有两个缺点：

- 数量太多了，我们要统计、存储的特征对儿的量是`"所有用户特征 * 所有物料特征"`，要耗费大量的资源，线上检索起来也是个麻烦
- 扩展性太差。只有对共现超过一定次数的特征对上的xtr才置信，才有保留价值。对于共现次数较少，甚至没有共现过的特征对上的xtr，我们也拿不到。

为了克服以上缺点，阿里妈妈在SIGIR 21《Explicit Semantic Cross Feature Learning via Pre-trained Graph Neural Networks for CTR Prediction》一文中提出了用预训练来解决以上难题的思路

- 训练一个GNN模型

- - 图的顶点就是样本中出现过的categorical feature，样本中常见共现特征之间建立边，边上的值就是这一对儿特征离线统计出的xtr
  - 按照link prediction的方式来训练GNN

- 线下训练和线上预测时，将每个用户特征与每个物料特征两两组合，每对儿特征喂入训练好的GNN模型，返回预估xtr作为特征。

- 这种作法，即节省了存储+检索海量特征组合的开销，又因为GNN本身也是基于embedding的，对于罕见或少见特征对的扩展性也比较好。

此篇文章的重点是“用预估代替统计+存储”的思路，是否必须用GNN模型，我看倒也未必。如果担心GNN线上预估耗时问题，我看用FM模型也不错：

- 训练一个常规的FM模型预估xtr
- 模型训练好后，将每个categorical feature的embedding存储起来
- 线下训练或线上预估时，将所有用户特征与所有物料特征，两两组合。
- 针对每一对儿特征，获取各自的feature embedding，点积再sigmoid，就得到这一对儿特征上的预估xtr，供训练或预测

# 后记

多多少少受“DNN万能函数模拟器”、“DNN能让特征充分交叉”的神话影响，业界对特征工程的研究，远不如模型结构那么热闹。

本文希望传递这样一种思想，即便在DNN时代，特征工程仍然值得我们投入精力，深入研究。相比于粗犷地将原始特征一古脑地扔进DIN/DIEN/SIM这些“强但重”的模型，在原始特征上施以精细的刀工，挖掘出更加直白的信息喂到模型嘴边上，

- 一来，令模型对特征中的信息“吸收”更好
- 二来，离线挖掘出强有力的特征，某种程度上能够取代那些“强但重”的模型结构，节省预测耗时，适用于召回+粗排这些计算紧张的场景

其实输入侧的故事，还远没有结束。

- 挖掘出重要特征，如何接入DNN才能让它们发挥使用？是不是和其他特征一样，喂到DNN的最底层，让它们的信息慢慢逐层向上传递？关于这一点，请出门左转，看我的另一篇文章《先入为主：将先验知识注入推荐模型》。
- 如我之前所述，推荐系统中，ID类特征才是一等公民。而文中介绍的重要特征，大多是实数型的。如何将这些重要的实数型特征转化为id类特征再进行embedding，业界最近也有一些新的研究成果，突破了传统的bucketize + embedding table的老套路，准备在下一篇文章中总结一下。欲知后事如何，请听下回分解:-)